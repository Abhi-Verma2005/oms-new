async function testUltraOptimized() {
  try {
    console.log('ðŸš€ Testing Ultra-Optimized AI Chat System')
    console.log('==========================================')
    
    // Test 1: Basic Performance Test
    console.log('\n1. Testing Basic Performance...')
    
    const testMessage = 'Hello, ultra-optimized test!'
    const startTime = Date.now()
    
    try {
      const response = await fetch('http://localhost:3000/api/ai-chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          message: testMessage,
          messages: [],
          config: {
            systemPrompt: 'You are a helpful AI assistant.',
            navigationData: []
          },
          currentUrl: '/test',
          cartState: { items: [], totalItems: 0, totalPrice: 0 }
        })
      })
      
      const endTime = Date.now()
      const duration = endTime - startTime
      
      if (response.ok) {
        const data = await response.json()
        console.log(`âœ… Basic Performance: OK (${duration}ms)`)
        console.log(`   Response: "${data.response?.substring(0, 80)}..."`)
        
        if (duration < 1000) {
          console.log('ðŸŽ‰ EXCELLENT: Response time under 1 second!')
        } else if (duration < 2000) {
          console.log('âœ… GOOD: Response time under 2 seconds')
        } else if (duration < 3000) {
          console.log('âš ï¸ MODERATE: Response time under 3 seconds')
        } else {
          console.log('âŒ SLOW: Response time over 3 seconds')
        }
      } else {
        console.log(`âŒ Basic Performance: FAILED (${response.status})`)
      }
    } catch (error) {
      console.log(`âŒ Basic Performance: ERROR - ${error.message}`)
    }
    
    // Test 2: Streaming Performance Test
    console.log('\n2. Testing Streaming Performance...')
    
    const streamingStartTime = Date.now()
    
    try {
      const streamingResponse = await fetch('http://localhost:3000/api/ai-chat?stream=1', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          message: 'Tell me about SEO optimization in 2 sentences',
          messages: [],
          config: {
            systemPrompt: 'You are a helpful AI assistant.',
            navigationData: []
          }
        })
      })
      
      if (streamingResponse.ok) {
        const reader = streamingResponse.body?.getReader()
        let streamedText = ''
        let firstTokenTime = null
        
        if (reader) {
          try {
            while (true) {
              const { done, value } = await reader.read()
              if (done) break
              
              const chunk = new TextDecoder().decode(value)
              streamedText += chunk
              
              if (!firstTokenTime && chunk.trim()) {
                firstTokenTime = Date.now()
                const timeToFirstToken = firstTokenTime - streamingStartTime
                console.log(`âœ… First token received: ${timeToFirstToken}ms`)
              }
            }
            
            const streamingEndTime = Date.now()
            const totalStreamingTime = streamingEndTime - streamingStartTime
            
            console.log(`âœ… Streaming completed: ${totalStreamingTime}ms`)
            console.log(`   Streamed text length: ${streamedText.length} characters`)
            
            if (firstTokenTime && (firstTokenTime - streamingStartTime) < 300) {
              console.log('ðŸŽ‰ EXCELLENT: First token under 300ms!')
            } else if (firstTokenTime && (firstTokenTime - streamingStartTime) < 500) {
              console.log('âœ… GOOD: First token under 500ms')
            } else if (firstTokenTime && (firstTokenTime - streamingStartTime) < 1000) {
              console.log('âš ï¸ MODERATE: First token under 1 second')
            } else {
              console.log('âŒ SLOW: First token over 1 second')
            }
            
          } finally {
            reader.releaseLock()
          }
        }
      } else {
        console.log(`âŒ Streaming Performance: FAILED (${streamingResponse.status})`)
      }
    } catch (error) {
      console.log(`âŒ Streaming Performance: ERROR - ${error.message}`)
    }
    
    // Test 3: Multiple Rapid Requests
    console.log('\n3. Testing Multiple Rapid Requests...')
    
    const rapidStartTime = Date.now()
    const rapidRequests = 5
    
    const promises = []
    for (let i = 0; i < rapidRequests; i++) {
      const promise = fetch('http://localhost:3000/api/ai-chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          message: `Rapid test ${i + 1}`,
          messages: [],
          config: {
            systemPrompt: 'You are a helpful AI assistant.',
            navigationData: []
          }
        })
      }).then(response => response.ok)
      promises.push(promise)
    }
    
    try {
      const results = await Promise.all(promises)
      const rapidEndTime = Date.now()
      const rapidDuration = rapidEndTime - rapidStartTime
      
      const successCount = results.filter(Boolean).length
      console.log(`âœ… Rapid requests: ${successCount}/${rapidRequests} successful (${rapidDuration}ms)`)
      
      if (rapidDuration < 3000) {
        console.log('ðŸŽ‰ EXCELLENT: All rapid requests completed quickly!')
      } else if (rapidDuration < 5000) {
        console.log('âœ… GOOD: Rapid requests completed reasonably fast')
      } else {
        console.log('âš ï¸ MODERATE: Rapid requests took longer than expected')
      }
      
    } catch (error) {
      console.log(`âŒ Rapid requests: ERROR - ${error.message}`)
    }
    
    // Test 4: Performance Summary
    console.log('\n4. Performance Summary...')
    console.log('=========================')
    console.log('ULTRA-OPTIMIZATIONS APPLIED:')
    console.log('  âœ… Minimal system prompt (1 line)')
    console.log('  âœ… No user context fetching')
    console.log('  âœ… No database operations')
    console.log('  âœ… No background processing')
    console.log('  âœ… Reduced max tokens (512)')
    console.log('  âœ… Limited message history (5 messages)')
    console.log('  âœ… Minimal tool detection')
    console.log('')
    console.log('EXPECTED PERFORMANCE:')
    console.log('  ðŸŽ¯ Response Time: <1 second')
    console.log('  ðŸŽ¯ First Token: <300ms')
    console.log('  ðŸŽ¯ Streaming: Immediate start')
    console.log('  ðŸŽ¯ Concurrent: High throughput')
    
    console.log('\nðŸŽ‰ Ultra-Optimized AI Chat Test Complete!')
    
  } catch (error) {
    console.error('âŒ Test failed:', error)
  }
}

testUltraOptimized()
